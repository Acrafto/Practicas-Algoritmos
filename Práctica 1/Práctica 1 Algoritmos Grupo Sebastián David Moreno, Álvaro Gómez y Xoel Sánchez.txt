Análisis empírico de la complejidad de los algoritmos de Suma de la subsecuencia máxima
-------------------------------------------------------------------------------------------
										24/09/2025

Autores: Sebastián David Moreno Expósito, Álvaro Gómez García y Xoel Sánchez Dacoba.
Sujeto de Análisis: Algoritmos suma_sub_max1(O(n^2)) y suma_sub_max2(O(n))

-------------------------------------------------------------------------------------------

En este experimento nos disponemos a analizar y demostrar empíricamente la complejidad teórica de los
algoritmos presentados, cuyo objetivo es en ambos casos la resolución del problema de la subsecuencia
de suma máxima, esto es hallar en un vector numérico la suma más grande de cualquier subarreglo contiguo
del vector. Para ello analizaremos ambos algoritmos, presentados como suma_sub_max1 y suma_sub_max2, de complejidad
O(n^2) y O(n) respectivamente, en vectores generados pseudoaleatoriamente. Primeramente se someterán a análisis
vectores ya proporcionados en el material para la verificación del correcto funcionamiento de los algoritmos.
En el experimento se usaron medidas de tiempo del orden de microsegundos(µs).

El entorno físico de análisis se trata de un ordenador personal(PC) de las siguientes características:

CPU:AMD Ryzen 5 3600X 6-Core Processor
GPU:NVIDIA GeForce RTX 2060
RAM:32GB
SO: Windows 10 home version 22H2 (compilación 10.0.19045)

El entorno virtual es el lenguaje Python en su versión 3.12.10

-------------------------------------------------------------------------------------------

A continuación se exhiben las tablas de tiempos obtenidas para tamaños de entrada n siguiendo una progresión
geométrica de orden (*2) y sus respectivos análisis.
Cada tiempo se calculó como el promedio de 1000 ejecuciones del algoritmo en cuestión sobre el vector de n elementos
como garante de fiabilidad cuando caían por debajo de un umbral mínimo establecido en 1000 microsegundo(µs)[1 milisegundo(ms)].
La función proporcionada para calcular el tiempo actual del PC es monótanamente creciente, es un cronómetro, por lo que en
condiciones normales una resta entre un instante de tiempo posterior con uno anterior no puede ser negativa, sin embargo se agregó
una sección en el código que notifica esto en caso que ocurra haciendo el código más robusto y evitar mediciones anómalas.
Además es preciso ejecutar el programa al menos 2 veces pues los tiempos en la primera ejecución pueden contaminarse ya que python
en la primera ejecución compila internamente el código para guardarlo a bytecode y el tiempo que demora en hacerlo afectaría
las mediciones, además de otros procesos que se llevan a cabo en la primera ejecución y se guardan en caché para evitar tener que hacerlos en la segunda.

SumaSubMax2
n[-]                             t(n)[µs]       t(n)/n^0.8[µs]          t(n)/n[µs]       t(n)/n^1.2[µs]
*                 500               29.841  0.20684135264592718             0.059682  0.01722064315687087
*                1000                59.96  0.23870505946387688              0.05996 0.015061271043331447
*                2000              119.805   0.2739371587307666 0.059902500000000004  0.01309902432687745
*                4000              238.517   0.3132357661614866           0.05962925 0.011351345662517384
*                8000              462.514    0.348861379265106 0.057814250000000005 0.009581133658599921
*               16000              921.208   0.3990816091707911 0.057575499999999995  0.00830641684325608
                32000                 1828  0.45483744235737045             0.057125 0.007174575619999242
                64000                 3593   0.5134678286171509          0.056140625 0.006138203018247187
               128000                 7268   0.5965501275752053           0.05678125 0.005404592510385551
               256000                14998   0.7070357554336274         0.0585859375 0.0048545098976626126

Si (*) -> 't(n)<1000' : tiempo promedio de K=1000 ejecuciones.

SumaSubMax1
n[-]                             t(n)[µs]       t(n)/n^1.8[µs]        t(n)/n^2[µs]       t(n)/n^2.2[µs]
                  500                 6079  0.08427255003080267             0.024316 0.007016138182407953
                 1000                23358  0.09298987289788586             0.023358  0.00586726432672007
                 2000                93050  0.10638058770459426            0.0232625 0.005086867049021094
                 4000               365183  0.11989541289944758         0.0228239375 0.004344887851887997
                 8000              1468084  0.13841683957594636         0.0229388125 0.003801481962181679


En el caso del algoritmo suma_sub_max2, los cocientes t(n)/n se mantienen prácticamente constantes alrededor de 0.058,
lo que indica que la función n es una cota superior ajustada del algoritmo. La relación con n^0.8 crece de forma sostenida,
mientras que la relación con n^1.2 decrece tendiendo a cero a medida que n aumenta, confirmando que esas cotas son ligeramente
subestimada y ligeramente sobrestimada respectivamente.

En el caso del algoritmo suma_sub_max1, los cocientes t(n)/n² se mantienen estables en torno a 0.023,
lo que confirma que la cota ajustada es n². La relación con n^1.8 crece y con n^2.2 decrece, verificando
el comportamiento esperado.

-------------------------------------------------------------------------------------------

Discutidos los resultados obtenidos tras el análisis y procedemos a extraer la siguiente conclusión: Los resultados
experimentales confirman las complejidades teóricas. Esto es para suma_sub_max2 la complejidad temporal de la cota
superior se ajusta a O(n) y para suma_sub_max1, la complejidad se ajusta a O(n²).

De este modo, se valida empíricamente que el segundo algoritmo resulta más eficiente para grandes valores de n,
tal y como predice el análisis teórico.





