Práctica 3: Ordenación Rápida (Quicksort con Mediana de Tres y Umbral)
-----------------------------------------------------------------------------
										08/11/2025

Grupo:
Sebastián David Moreno Expósito, Álvaro Gómez García y Xoel Sánchez Dacoba

Sujeto de Análisis:
Algoritmos ord_rapida(), ord_rapida_aux() y mediana3()

------------------------------------------------------------------------


e1. INTRODUCCIÓN
------------------------------------------------------------
En esta práctica se ha implementado y analizado empíricamente el comportamiento
del algoritmo de **ordenación rápida (Quicksort)** con **selección del pivote
mediante mediana de tres** y un **umbral** para la
ordenación por inserción de los subvector pequeños.

El objetivo es comprobar el efecto de la elección del umbral sobre el
rendimiento temporal del algoritmo y comparar las mediciones obtenidas en
distintas situaciones iniciales del vector:
ascendente, descendente y aleatoria.
También se comparan los resultados empíricos con las
complejidades teóricas esperadas y con los obtenidos en
la práctica anterior (ordenación de Shell).

El experimento se ha realizado con tres valores de umbral:
• UMBRAL = 1  → Quicksort puro
• UMBRAL = 10 → Quicksort + Inserción para subvectores pequeños
• UMBRAL = 100 → Quicksort con inserción más agresiva


e3. CARACTERÍSTICAS DE LA MÁQUINA
------------------------------------------------------------
• Sistema operativo: Windows 11 Home 64 bits
• Procesador: 11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz (2.80 GHz)
• Memoria RAM: 16 GB
• Versión de Python: 3.13.9
• Módulos utilizados: time, random, typing, math


e4. UNIDADES DE TIEMPO
------------------------------------------------------------
Los tiempos se expresan en **microsegundos (µs)**, obtenidos con
la función `time.perf_counter_ns()` y
dividiendo por 1000.
Cuando el tiempo medido es menor que el umbral de confianza (1000 µs),
se repiten **K = 1000** ejecuciones y se resta el tiempo de generación de
los vectores para mayor precisión. Dichos valores
se indican con un asterisco (*) en las tablas.


e5–e6. TAMAÑOS DE ENTRADA Y NÚMERO DE MUESTRAS
------------------------------------------------------------
Se ha seguido una **progresión geométrica de razón 2**,
partiendo de un tamaño inicial de 500 y
realizando seis mediciones sucesivas:

n = 500, 1000, 2000, 4000, 8000, 16000

Cada tabla incluye al menos cinco valores válidos de la progresión geométrica.


e7. FORMATO DE LOS DATOS Y PRECISIÓN
------------------------------------------------------------
Todas las mediciones se muestran con tres o más cifras significativas.
Se incluyen tres columnas de normalización:

- t(n)/n       	  → Cota subestimada
- t(n)/(n·log₂n)  → Cota teórica ajustada Θ(n·log n)
- t(n)/n^1.3-1.6  → Cota sobreestimada


e8–e9–e10–e11. RESULTADOS Y ESTUDIO DE COTAS
------------------------------------------------------------

==============================
ORDENACIÓN RÁPIDA (UMBRAL = 1)
==============================

**Caso 1: Inicialización ASCENDENTE**

    n[-]       t(n)[µs]         t(n)/n      t(n)/(n·log2n)      t(n)/n^α (α=1.35)
*     500        271.106       0.542212            0.0604757              0.0615928
*    1000        620.649       0.620649             0.062278              0.0553154
     2000       1260.000           0.63            0.0574514              0.0440535
     4000       3268.000          0.817             0.068278               0.044823
     8000       6191.000       0.773875            0.0596859              0.0333111
    16000      13626.000       0.851625            0.0609794              0.0287612

Nota: Si (*) -> 't(n)<1000': tiempo promedio de K=1000 ejecuciones.
Estimación constante ajustada (c en t ≈ c·n·log2n): c ≈ 0.0629811

**Caso 2: Inicialización DESCENDENTE**

    n[-]       t(n)[µs]         t(n)/n      t(n)/(n·log2n)      t(n)/n^α (α=1.35)
*     500        292.508       0.585016            0.0652498              0.0664551
*    1000        622.832       0.622832             0.062497                0.05551
     2000       1783.000         0.8915            0.0812983              0.0623391
     4000       3258.000         0.8145            0.0680691              0.0446859
     8000       8784.000          1.098            0.0846844               0.047263
    16000      14164.000        0.88525            0.0633871              0.0298967

Nota: Si (*) -> 't(n)<1000': tiempo promedio de K=1000 ejecuciones.
Estimación constante ajustada (c en t ≈ c·n·log2n): c ≈ 0.0720469


**Caso 3: Inicialización ALEATORIA**

    n[-]       t(n)[µs]         t(n)/n      t(n)/(n·log2n)       t(n)/n^α (α=1.6)
*     500        385.005        0.77001            0.0858832              0.0184976
     1000       1229.000          1.229             0.123322              0.0194783
     2000       2900.000           1.45             0.132229              0.0151618
     4000       5554.000         1.3885             0.116039             0.00957877
     8000      12271.000        1.53388             0.118302             0.00698129
    16000      25268.000        1.57925              0.11308             0.00474219

Nota: Si (*) -> 't(n)<1000': tiempo promedio de K=1000 ejecuciones.
Estimación constante ajustada (c en t ≈ c·n·log2n): c ≈ 0.115807


==============================
ORDENACIÓN RÁPIDA (UMBRAL = 10)
==============================

**Caso 4: Inicialización ASCENDENTE**

    n[-]       t(n)[µs]         t(n)/n      t(n)/(n·log2n)      t(n)/n^α (α=1.35)
*     500        237.340        0.47468            0.0529435              0.0539214
*    1000        474.685       0.474685            0.0476315              0.0423063
     2000       1121.000         0.5605            0.0511135              0.0391936
     4000       2520.000           0.63            0.0526501              0.0345636
     8000       5002.000        0.62525            0.0482231              0.0269136
    16000      11226.000       0.701625            0.0502389              0.0236953

Nota: Si (*) -> 't(n)<1000': tiempo promedio de K=1000 ejecuciones.
Estimación constante ajustada (c en t ≈ c·n·log2n): c ≈ 0.0503707


**Caso 5: Inicialización DESCENDENTE**

    n[-]       t(n)[µs]         t(n)/n      t(n)/(n·log2n)      t(n)/n^α (α=1.35)
*     500        201.289       0.402578            0.0449016               0.045731
*    1000        479.341       0.479341            0.0480987              0.0427213
     2000       1026.000          0.513            0.0467819              0.0358721
     4000       2442.000         0.6105            0.0510205              0.0334938
     8000       5176.000          0.647            0.0499006              0.0278498
    16000      10545.000       0.659062            0.0471912              0.0222579

Nota: Si (*) -> 't(n)<1000': tiempo promedio de K=1000 ejecuciones.
Estimación constante ajustada (c en t ≈ c·n·log2n): c ≈ 0.0493708


**Caso 6: Inicialización ALEATORIA**

    n[-]       t(n)[µs]         t(n)/n      t(n)/(n·log2n)       t(n)/n^α (α=1.6)
*     500        341.819       0.683638            0.0762497              0.0164227
     1000       1416.000          1.416             0.142086              0.0224421
     2000       2735.000         1.3675             0.124706              0.0142991
     4000       6339.000        1.58475              0.13244              0.0109326
     8000      14225.000        1.77812              0.13714             0.00809298
    16000      26137.000        1.63356             0.116969             0.00490528

Nota: Si (*) -> 't(n)<1000': tiempo promedio de K=1000 ejecuciones.
Estimación constante ajustada (c en t ≈ c·n·log2n): c ≈ 0.12885


==============================
ORDENACIÓN RÁPIDA (UMBRAL = 100)
==============================

**Caso 7: Inicialización ASCENDENTE**

    n[-]       t(n)[µs]         t(n)/n      t(n)/(n·log2n)      t(n)/n^α (α=1.35)
*     500        116.115        0.23223            0.0259018              0.0263802
*    1000        280.447       0.280447             0.028141              0.0249949
*    2000        650.870       0.325435            0.0296773              0.0227564
     4000       1448.000          0.362            0.0302529              0.0198604
     8000       3826.000        0.47825            0.0368855              0.0205861
    16000       7390.000       0.461875            0.0330719              0.0155985

Nota: Si (*) -> 't(n)<1000': tiempo promedio de K=1000 ejecuciones.
Estimación constante ajustada (c en t ≈ c·n·log2n): c ≈ 0.0334035


**Caso 8: Inicialización DESCENDENTE**

    n[-]       t(n)[µs]         t(n)/n      t(n)/(n·log2n)      t(n)/n^α (α=1.35)
*     500        122.211       0.244422            0.0272616              0.0277652
*    1000        285.342       0.285342            0.0286322              0.0254311
*    2000        699.230       0.349615            0.0318824              0.0244472
     4000       1528.000          0.382            0.0319244              0.0209576
     8000       3602.000        0.45025             0.034726              0.0193808
    16000       7671.000       0.479438            0.0343294              0.0161916

Nota: Si (*) -> 't(n)<1000': tiempo promedio de K=1000 ejecuciones.
Estimación constante ajustada (c en t ≈ c·n·log2n): c ≈ 0.0336599

**Caso 9: Inicialización ALEATORIA**

    n[-]       t(n)[µs]         t(n)/n      t(n)/(n·log2n)       t(n)/n^α (α=1.6)
      500       1170.000           2.34             0.260992              0.0562126
     1000       2032.000          2.032             0.203898               0.032205
     2000       4452.000          2.226             0.202995              0.0232759
     4000      11265.000        2.81625             0.235359              0.0194283
     8000      19396.000         2.4245             0.186992              0.0110349
    16000      39342.000        2.45887             0.176064             0.00738354

Nota: Si (*) -> 't(n)<1000': tiempo promedio de K=1000 ejecuciones.
Estimación constante ajustada (c en t ≈ c·n·log2n): c ≈ 0.199472


e12. OBSERVACIONES Y MEDICIONES ANÓMALAS
------------------------------------------------------------
Las mediciones se repitieron múltiples veces para eliminar resultados anómalos.
Los casos marcados con (*) indican tiempos menores que el umbral de confianza,
corregidos mediante
1000 repeticiones.
No se observaron tiempos negativos ni desviaciones irregulares.
La función de medición automatiza el cálculo de medias y
la resta del tiempo de generación de
vectores, garantizando estabilidad en los resultados.


e2. CONCLUSIONES
------------------------------------------------------------
Los resultados obtenidos confirman la corrección del algoritmo y su coherencia
con las complejidades
teóricas:

• En todos los casos, la cota ajustada corresponde a Θ(n·log n),
como predice la teoría.
• La cota subestimada n y la sobrestimada n, n^1.35-n^1.6 delimitan correctamente
el comportamiento.
• A medida que el **umbral aumenta**, los tiempos de ejecución disminuyen,
ya que los subproblemas
pequeños se resuelven con inserción, evitando llamadas recursivas innecesarias.
• El mejor rendimiento global se obtiene con **UMBRAL = 100**, especialmente
en vectores
ascendentes y descendentes, donde la inserción es muy eficiente.
• En vectores aleatorios el comportamiento es también Θ(n·log n),
aunque ligeramente más costoso por la menor localidad de referencia.
• Comparado con la **ordenación de Shell** (práctica anterior),
Quicksort resulta más eficiente
para entradas grandes, confirmando su mejor complejidad asintótica.

En conjunto, las mediciones experimentales validan las
hipótesis teóricas y demuestran una
implementación correcta, eficiente y ajustada al diseño solicitado.
